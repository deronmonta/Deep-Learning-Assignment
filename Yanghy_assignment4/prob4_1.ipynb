{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Neural Network.\n",
    "A 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\n",
    "implementation with TensorFlow. This example is using the MNIST database\n",
    "of handwritten digits (http://yann.lecun.com/exdb/mnist/).\n",
    "This example is using TensorFlow layers, see 'neural_network_raw' example for\n",
    "a raw implementation with variables.\n",
    "Links:\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "Author: Aymeric Damien\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.5\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "\n",
    "# Define the neural network\n",
    "def neural_net(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn_l2(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "    # TODO: IMPLEMENT THIS FUNCTION\n",
    "    # Define loss and optimizer\n",
    "    # Compare the use of squared loss, cross entropy loss, and softmax with log-likelihood \n",
    "    #Squared loss\n",
    "    #loss_op_l2 = tf.reduce_mean(tf.nn.l2_loss(pred_probas-tf.cast(labels, dtype=tf.float32)))\n",
    "    #print(1- tf.multiply(tf.cast(tf.argmax(logits, axis=1), dtype=tf.float32),tf.cast(labels, dtype=tf.float32)))\n",
    "    loss_op_l2 = tf.reduce_mean(tf.square(1 - tf.cast(tf.one_hot(labels,10),\n",
    "    dtype = tf.float64)*tf.cast(tf.sigmoid(logits),dtype = tf.float64)))\n",
    "                                                                                                          \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "    train_op_l2 = optimizer.minimize(loss_op_l2, global_step=tf.train.get_global_step())\n",
    "#----------------------------------------------------------------------------------------------------------------------------   \n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op_l2,\n",
    "        train_op=train_op_l2,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "#For softmax with log likelihood\n",
    "def model_fn_log(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "    # TODO: IMPLEMENT THIS FUNCTION\n",
    "    # Define loss and optimizer\n",
    "    # Compare the use of squared loss, cross entropy loss, and softmax with log-likelihood \n",
    "    #Squared loss\n",
    "    loss_op_log = tf.reduce_mean(tf.losses.log_loss(labels = \n",
    "    tf.one_hot(labels,10), predictions =  tf.nn.softmax(logits)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    train_op_log = optimizer.minimize(loss_op_log, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op_log,\n",
    "        train_op=train_op_log,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def model_fn_cross(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "    # TODO: IMPLEMENT THIS FUNCTION\n",
    "    # Define loss and optimizer\n",
    "    # Compare the use of squared loss, cross entropy loss, and softmax with log-likelihood \n",
    "    \n",
    "    #cross entropy\n",
    "    loss_op_cross = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    #train_op_log = optimizer.minimize(loss_op_log, global_step=tf.train.get_global_step())\n",
    "    #train_op_l2 = optimizer.minimize(loss_op_l2, global_step=tf.train.get_global_step())\n",
    "    train_op_cross = optimizer.minimize(loss_op_cross, global_step=tf.train.get_global_step())\n",
    "#----------------------------------------------------------------------------------------------------------------------------   \n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    print(tf.trainable_variables())\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op_cross,\n",
    "        train_op=train_op_cross,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_sygsgzl\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FURRYM~1\\\\AppData\\\\Local\\\\Temp\\\\tmp_sygsgzl', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "{'images': <tf.Tensor 'random_shuffle_queue_DequeueMany:1' shape=(128, 784) dtype=float32>}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_sygsgzl\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.925339738418, step = 1\n",
      "INFO:tensorflow:global_step/sec: 210.83\n",
      "INFO:tensorflow:loss = 0.9006195596, step = 101 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.009\n",
      "INFO:tensorflow:loss = 0.900179887677, step = 201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.563\n",
      "INFO:tensorflow:loss = 0.900181628176, step = 301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.47\n",
      "INFO:tensorflow:loss = 0.900090328456, step = 401 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.792\n",
      "INFO:tensorflow:loss = 0.90006312192, step = 501 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.565\n",
      "INFO:tensorflow:loss = 0.90006879758, step = 601 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.875\n",
      "INFO:tensorflow:loss = 0.900066113421, step = 701 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.514\n",
      "INFO:tensorflow:loss = 0.900055858622, step = 801 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.52\n",
      "INFO:tensorflow:loss = 0.900038662813, step = 901 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.283\n",
      "INFO:tensorflow:loss = 0.900029939548, step = 1001 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.864\n",
      "INFO:tensorflow:loss = 0.900048009579, step = 1101 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.402\n",
      "INFO:tensorflow:loss = 0.900030077997, step = 1201 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.096\n",
      "INFO:tensorflow:loss = 0.900005956408, step = 1301 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.181\n",
      "INFO:tensorflow:loss = 0.900029396782, step = 1401 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.416\n",
      "INFO:tensorflow:loss = 0.90002466249, step = 1501 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.463\n",
      "INFO:tensorflow:loss = 0.900031775235, step = 1601 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.351\n",
      "INFO:tensorflow:loss = 0.9000132298, step = 1701 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.998\n",
      "INFO:tensorflow:loss = 0.900025762997, step = 1801 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.797\n",
      "INFO:tensorflow:loss = 0.900005337479, step = 1901 (0.522 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_sygsgzl\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.900012527638.\n",
      "{'images': <tf.Tensor 'fifo_queue_DequeueUpTo:1' shape=(?, 784) dtype=float32>}\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-01:27:24\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_sygsgzl\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-01:27:24\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.4061, global_step = 2000, loss = 0.900015\n",
      "Testing Accuracy: 0.4061\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn_l2)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpfj4hgfc2\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FURRYM~1\\\\AppData\\\\Local\\\\Temp\\\\tmpfj4hgfc2', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpfj4hgfc2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.338691, step = 1\n",
      "INFO:tensorflow:global_step/sec: 191.062\n",
      "INFO:tensorflow:loss = 0.0712233, step = 101 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.672\n",
      "INFO:tensorflow:loss = 0.0540964, step = 201 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.523\n",
      "INFO:tensorflow:loss = 0.0578944, step = 301 (0.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.157\n",
      "INFO:tensorflow:loss = 0.038522, step = 401 (0.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.551\n",
      "INFO:tensorflow:loss = 0.0500489, step = 501 (0.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.472\n",
      "INFO:tensorflow:loss = 0.0594151, step = 601 (0.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.554\n",
      "INFO:tensorflow:loss = 0.0784393, step = 701 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.769\n",
      "INFO:tensorflow:loss = 0.0515773, step = 801 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.97\n",
      "INFO:tensorflow:loss = 0.060755, step = 901 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.873\n",
      "INFO:tensorflow:loss = 0.0477099, step = 1001 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.029\n",
      "INFO:tensorflow:loss = 0.0467748, step = 1101 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.157\n",
      "INFO:tensorflow:loss = 0.0452153, step = 1201 (0.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.59\n",
      "INFO:tensorflow:loss = 0.0590578, step = 1301 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.889\n",
      "INFO:tensorflow:loss = 0.035821, step = 1401 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.037\n",
      "INFO:tensorflow:loss = 0.0654302, step = 1501 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.238\n",
      "INFO:tensorflow:loss = 0.0359334, step = 1601 (0.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.873\n",
      "INFO:tensorflow:loss = 0.0403784, step = 1701 (0.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.987\n",
      "INFO:tensorflow:loss = 0.0609189, step = 1801 (0.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.704\n",
      "INFO:tensorflow:loss = 0.0357213, step = 1901 (0.928 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpfj4hgfc2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0471059.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-17:38:03\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpfj4hgfc2\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-17:38:04\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9216, global_step = 2000, loss = 0.0473391\n",
      "Testing Accuracy: 0.9216\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator for log loss function\n",
    "model = tf.estimator.Estimator(model_fn_log)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_pul66z6\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FURRYM~1\\\\AppData\\\\Local\\\\Temp\\\\tmp_pul66z6', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "[<tf.Variable 'dense/kernel:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'dense_2/kernel:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32_ref>]\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_pul66z6\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.30048, step = 1\n",
      "INFO:tensorflow:global_step/sec: 200.069\n",
      "INFO:tensorflow:loss = 0.452207, step = 101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.682\n",
      "INFO:tensorflow:loss = 0.481064, step = 201 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.895\n",
      "INFO:tensorflow:loss = 0.343033, step = 301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.482\n",
      "INFO:tensorflow:loss = 0.198983, step = 401 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.563\n",
      "INFO:tensorflow:loss = 0.2612, step = 501 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.793\n",
      "INFO:tensorflow:loss = 0.368077, step = 601 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.146\n",
      "INFO:tensorflow:loss = 0.279265, step = 701 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.107\n",
      "INFO:tensorflow:loss = 0.203365, step = 801 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.97\n",
      "INFO:tensorflow:loss = 0.48232, step = 901 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.245\n",
      "INFO:tensorflow:loss = 0.169321, step = 1001 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.723\n",
      "INFO:tensorflow:loss = 0.285919, step = 1101 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.885\n",
      "INFO:tensorflow:loss = 0.27082, step = 1201 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.173\n",
      "INFO:tensorflow:loss = 0.155495, step = 1301 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.714\n",
      "INFO:tensorflow:loss = 0.2242, step = 1401 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.729\n",
      "INFO:tensorflow:loss = 0.228789, step = 1501 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.224\n",
      "INFO:tensorflow:loss = 0.301604, step = 1601 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.335\n",
      "INFO:tensorflow:loss = 0.244006, step = 1701 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.768\n",
      "INFO:tensorflow:loss = 0.123931, step = 1801 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.508\n",
      "INFO:tensorflow:loss = 0.26189, step = 1901 (0.554 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_pul66z6\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.280673.\n",
      "[<tf.Variable 'dense/kernel:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'dense_1/kernel:0' shape=(256, 256) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'dense_2/kernel:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32_ref>]\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-01:21:10\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp_pul66z6\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-01:21:10\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9134, global_step = 2000, loss = 0.299863\n",
      "Testing Accuracy: 0.9134\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator for Cross entropy loss function\n",
    "model = tf.estimator.Estimator(model_fn_cross)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the cross entropy and softmax with log-liklihood converged faster than squared loss. The cross entropy converged the fastest. We need a higher learning rate in order for the squared loss to converge in the given step, However,  if the learning rate was set too high the log-likelihood and cross entropy would throw a nan error (\"ERROR:tensorflow:Model diverged with loss = NaN.\"). I looked it up and it was due to excessive learning rate. In the end, I made a compromise so that the squared loss would not get stuck while the other two loss functions still worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "\n",
    "def neural_net_dropout(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    layer_3 = tf.nn.dropout(layer_2, 0.7)\n",
    "    out_layer = tf.layers.dense(layer_3, num_classes)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "def model_fn_dropout(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net_dropout(features)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "    #Here we used the cross entropy as loss function\n",
    "    \n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "  \n",
    "    #cross entropy\n",
    "    loss_op_cross = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "    (logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op_cross, global_step=tf.train.get_global_step())\n",
    "#----------------------------------------------------------------------------------------------------------------------------   \n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op_cross,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp7kwuqvdx\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FURRYM~1\\\\AppData\\\\Local\\\\Temp\\\\tmp7kwuqvdx', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp7kwuqvdx\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.45908, step = 1\n",
      "INFO:tensorflow:global_step/sec: 198.987\n",
      "INFO:tensorflow:loss = 0.497305, step = 101 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.712\n",
      "INFO:tensorflow:loss = 0.454024, step = 201 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.672\n",
      "INFO:tensorflow:loss = 0.2435, step = 301 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.657\n",
      "INFO:tensorflow:loss = 0.503302, step = 401 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.865\n",
      "INFO:tensorflow:loss = 0.495814, step = 501 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.262\n",
      "INFO:tensorflow:loss = 0.326575, step = 601 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.895\n",
      "INFO:tensorflow:loss = 0.365319, step = 701 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.665\n",
      "INFO:tensorflow:loss = 0.40606, step = 801 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.615\n",
      "INFO:tensorflow:loss = 0.202165, step = 901 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.056\n",
      "INFO:tensorflow:loss = 0.25692, step = 1001 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.601\n",
      "INFO:tensorflow:loss = 0.320729, step = 1101 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.566\n",
      "INFO:tensorflow:loss = 0.261284, step = 1201 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.14\n",
      "INFO:tensorflow:loss = 0.154964, step = 1301 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.451\n",
      "INFO:tensorflow:loss = 0.252937, step = 1401 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.434\n",
      "INFO:tensorflow:loss = 0.19797, step = 1501 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.906\n",
      "INFO:tensorflow:loss = 0.35949, step = 1601 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.542\n",
      "INFO:tensorflow:loss = 0.292186, step = 1701 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.044\n",
      "INFO:tensorflow:loss = 0.25555, step = 1801 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.924\n",
      "INFO:tensorflow:loss = 0.194707, step = 1901 (0.584 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp7kwuqvdx\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.307408.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-01:45:00\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmp7kwuqvdx\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-01:45:01\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9149, global_step = 2000, loss = 0.294173\n",
      "Testing Accuracy: 0.9149\n"
     ]
    }
   ],
   "source": [
    "e_lis = []\n",
    "# Build the Estimator\n",
    "model_dropout = tf.estimator.Estimator(model_fn_dropout)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model_dropout.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e_drop = model_dropout.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e_drop['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_l1(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    \n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "def model_fn_l1(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net_l1(features)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "    # TODO: IMPLEMENT THIS FUNCTION\n",
    "    # Define loss and optimizer\n",
    "    # Compare the use of squared loss, cross entropy loss, and softmax with log-likelihood \n",
    "\n",
    "    #Squared loss\n",
    "    loss_op_l2 = tf.reduce_mean(tf.nn.l2_loss(tf.cast(labels, dtype=tf.float32)))    \n",
    "    \n",
    "    #log-likelihood \n",
    "    loss_op_log = tf.reduce_mean(tf.nn.log_softmax(logits = logits))              \n",
    "                                \n",
    "    #cross entropy\n",
    "    loss_op_cross = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "    (logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    \n",
    "    l1_regularize = tf.contrib.layers.l1_regularizer(scale=0.005, scope=None)\n",
    "    weights = tf.trainable_variables()\n",
    "    l1_penalty = tf.contrib.layers.apply_regularization(l1_regularize, weights)\n",
    "    total_loss = loss_op_cross + l1_penalty\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(total_loss, global_step=tf.train.get_global_step())\n",
    "#----------------------------------------------------------------------------------------------------------------------------   \n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op_cross,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpaioc4711\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FURRYM~1\\\\AppData\\\\Local\\\\Temp\\\\tmpaioc4711', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpaioc4711\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.32994, step = 1\n",
      "INFO:tensorflow:global_step/sec: 191.981\n",
      "INFO:tensorflow:loss = 0.985597, step = 101 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.89\n",
      "INFO:tensorflow:loss = 1.07709, step = 201 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.712\n",
      "INFO:tensorflow:loss = 0.831151, step = 301 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.868\n",
      "INFO:tensorflow:loss = 0.724401, step = 401 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.918\n",
      "INFO:tensorflow:loss = 0.604774, step = 501 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.269\n",
      "INFO:tensorflow:loss = 0.544938, step = 601 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.177\n",
      "INFO:tensorflow:loss = 0.485417, step = 701 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.096\n",
      "INFO:tensorflow:loss = 0.549745, step = 801 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.842\n",
      "INFO:tensorflow:loss = 0.524489, step = 901 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.186\n",
      "INFO:tensorflow:loss = 0.557964, step = 1001 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.324\n",
      "INFO:tensorflow:loss = 0.498183, step = 1101 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.78\n",
      "INFO:tensorflow:loss = 0.491438, step = 1201 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.612\n",
      "INFO:tensorflow:loss = 0.570596, step = 1301 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.3\n",
      "INFO:tensorflow:loss = 0.608689, step = 1401 (0.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.905\n",
      "INFO:tensorflow:loss = 0.38909, step = 1501 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.36\n",
      "INFO:tensorflow:loss = 0.544448, step = 1601 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.7\n",
      "INFO:tensorflow:loss = 0.525605, step = 1701 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.382\n",
      "INFO:tensorflow:loss = 0.54221, step = 1801 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.362\n",
      "INFO:tensorflow:loss = 0.701737, step = 1901 (0.602 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpaioc4711\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.464972.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-01:45:26\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpaioc4711\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-01:45:27\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.8463, global_step = 2000, loss = 0.515701\n",
      "Testing Accuracy: 0.8463\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model_l1 = tf.estimator.Estimator(model_fn_l1)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model_l1.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e_l1 = model_l1.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e_l1['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_l2(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    \n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "def model_fn_l2(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net_l2(features)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "    # TODO: IMPLEMENT THIS FUNCTION\n",
    "    # Define loss and optimizer\n",
    "    # Compare the use of squared loss, cross entropy loss, and softmax with log-likelihood \n",
    "\n",
    "    #Squared loss\n",
    "    loss_op_l2 = tf.reduce_mean(tf.nn.l2_loss(tf.cast(labels, dtype=tf.float32)))    \n",
    "    \n",
    "    #log-likelihood \n",
    "    loss_op_log = tf.reduce_mean(tf.nn.log_softmax(logits = logits))              \n",
    "                                \n",
    "    #cross entropy\n",
    "    loss_op_cross = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "    (logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "\n",
    "    l2_regularize = tf.contrib.layers.l2_regularizer(scale=0.05, scope=None)\n",
    "    weights = tf.trainable_variables()\n",
    "    l2_penalty = tf.contrib.layers.apply_regularization(l2_regularize, weights)\n",
    "    total_loss = loss_op_cross + l2_penalty\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(total_loss, global_step=tf.train.get_global_step())\n",
    "#----------------------------------------------------------------------------------------------------------------------------   \n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op_cross,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpg9shc2my\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FURRYM~1\\\\AppData\\\\Local\\\\Temp\\\\tmpg9shc2my', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpg9shc2my\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.29429, step = 1\n",
      "INFO:tensorflow:global_step/sec: 186.049\n",
      "INFO:tensorflow:loss = 0.851012, step = 101 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.943\n",
      "INFO:tensorflow:loss = 0.948308, step = 201 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.97\n",
      "INFO:tensorflow:loss = 0.821229, step = 301 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.428\n",
      "INFO:tensorflow:loss = 0.870117, step = 401 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.637\n",
      "INFO:tensorflow:loss = 0.971958, step = 501 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.701\n",
      "INFO:tensorflow:loss = 0.883126, step = 601 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.876\n",
      "INFO:tensorflow:loss = 0.924685, step = 701 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.05\n",
      "INFO:tensorflow:loss = 0.873827, step = 801 (0.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.924\n",
      "INFO:tensorflow:loss = 0.866419, step = 901 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.551\n",
      "INFO:tensorflow:loss = 0.919548, step = 1001 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.259\n",
      "INFO:tensorflow:loss = 0.772674, step = 1101 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.434\n",
      "INFO:tensorflow:loss = 0.824692, step = 1201 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.434\n",
      "INFO:tensorflow:loss = 0.863869, step = 1301 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.097\n",
      "INFO:tensorflow:loss = 0.853693, step = 1401 (0.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.451\n",
      "INFO:tensorflow:loss = 0.786578, step = 1501 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.186\n",
      "INFO:tensorflow:loss = 0.951829, step = 1601 (0.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.308\n",
      "INFO:tensorflow:loss = 0.97018, step = 1701 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.486\n",
      "INFO:tensorflow:loss = 0.851353, step = 1801 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.162\n",
      "INFO:tensorflow:loss = 0.918537, step = 1901 (0.549 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpg9shc2my\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.834183.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-01-01:49:19\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FURRYM~1\\AppData\\Local\\Temp\\tmpg9shc2my\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-01-01:49:20\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.8141, global_step = 2000, loss = 0.85111\n",
      "Testing Accuracy: 0.8141\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model_l2 = tf.estimator.Estimator(model_fn_l2)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model_l2.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e_l2 = model_l2.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e_l2['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8463\n",
      "0.8671\n",
      "0.9149\n"
     ]
    }
   ],
   "source": [
    "print(e_l1['accuracy'])\n",
    "print(e_l2['accuracy'])\n",
    "print(e_drop['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the dropout layer I used 70% keep probability for each elements. For both L1 and L2 regularizations, I used 0.05 scaling factor. \n",
    "We can see that the dropout regularizations performed the best. The final results were pretty sensitive to the parameters. I tried scaling factor 0.01 and 0.1. The performance results differed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
